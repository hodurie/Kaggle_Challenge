{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 차원 축소 기법\n",
    "\n",
    "## __차원(Dimensionality)__\n",
    "먼저 차원에 대해 알아보겠습니다.  \n",
    "\n",
    "__차원__이란,   \n",
    "데이터의 관점으로 봤을 땐 변수의 개수를 차원이라 정의합니다.  \n",
    "\n",
    "\n",
    "## 차원의 저주(Curse of Dimensionality)\n",
    "> 수많은 차원의 개수는 어떤 문제를 초래할까?  \n",
    "\n",
    "차원의 크기가 커지면 그만큼 부피가 증가 하게 됩니다.  \n",
    "\n",
    "이를 동일한 데이터가 있을 때  \n",
    "고차원에 데이터의 분포가  \n",
    "낮은 차원의 데이터의 분포보다 \n",
    "훨씬 적어지게 됩니다.  \n",
    "\n",
    "저차원 만큼의 정보량을 얻기 위해서는  \n",
    "많은 데이터를 확보해야 하는데  \n",
    "이는 모델 적합시 계산량을 늘려  \n",
    "모델 적합 시간을 늘리기도 합니다.  \n",
    "\n",
    "이와 같은 문제를 __차원의 저주__라고 합니다.  \n",
    "\n",
    "위와 같은 문제를 줄이기위해 사용하는 방법이   \n",
    "__차원 축소__입니다.  \n",
    "\n",
    "__차원 축소__ 방법에는 여러가지가 있습니다.  \n",
    "1. PCA\n",
    "2. t-SNE\n",
    "3. NMF\n",
    "\n",
    "\n",
    "## PCA(Principal Component Analysis)\n",
    "주성분 분석은  \n",
    "고차원 데이터의 분산을 최대한 보존하는 축을 찾아  \n",
    "선형 연관성이 없는 저차원 공간으로 변환하는 기법입니다.  \n",
    "\n",
    "차원을 축소하기 위해서 위 알고리즘은 공분산을 사용합니다.  \n",
    "\n",
    "__공분산__이란,  \n",
    "데이터의 구조가 얼만큼 닮아 있는 가를 나타내 주는 척도입니다.  \n",
    "\n",
    "__공분산__을 이용해 데이터가 가장 잘 분산돼 있는 축 하나를 찾습니다.\n",
    "> 아래 그림에서 $c_1$   \n",
    "\n",
    "이후, 첫 번째 축과 수직이 되면서 분산이 최대가 되는 다른 축 하나를 찾습니다.  \n",
    "> 아래 그림에서 $c_2$ \n",
    "\n",
    "![pca](./image/Dimensionality_Reduction/pca.png)\n",
    "\n",
    "더 많은 주성분 축을 사용하고 싶다면  \n",
    "이전에 구한 축들과 수직이 되는 축을 계속 찾아나가면 됩니다.  \n",
    "\n",
    "## t-SNE(t-distributed Stochastic Neighbor Embedding)\n",
    "고차원 데이터를 2차원 산점도를 이용해 시각화 용도로 많이 사용합니다.  \n",
    "\n",
    "__t-SNE__의 원리는  \n",
    "한 점을 선택 후,  \n",
    "그 점을 제외한 나머지 값들과의 거리를 구합니다.  \n",
    "이후, 기준점을 t-분포의 중앙에 위치하고  \n",
    "각각의 점들을 분포상에 위치해  \n",
    "가까운 점들을 같이 묶어 2차원 산점도에 나타냅니다.  \n",
    "\n",
    "![t-SNE](./image/Dimensionality_Reduction/t-SNE.png)\n",
    "\n",
    "## NMF(Non-negative Matrix Factorization)\n",
    "주로 특성 추출에 많이 이용하는 알고리즘으로  \n",
    "__PCA__와 __t-SNE__와 달리 추출된 특징에 대해서 해석이 가능합니다.  \n",
    "\n",
    "__NMF__는 모든 행렬의 값들이 양수인 데이터를 이용하며  \n",
    "__PCA__와 달리 주성분의 축을 따라 데이터를 회전 시키지 않습니다.  \n",
    "\n",
    "__NMF__는  \n",
    "모든 원소가 양수인 행렬 $V$를  \n",
    "가중치 행렬 $W$와 특성 행렬 $H$로 분해 합니다.  \n",
    "\n",
    "$$ W \\in \\mathbf{R}^{N \\times r} $$\n",
    "\n",
    "$$ H \\in \\mathbf{R}^{r \\times M} $$\n",
    "\n",
    "$$ V \\in \\mathbf{R}^{N \\times M} $$\n",
    "![NMF](./image/Dimensionality_Reduction/NMF.png)\n",
    "\n",
    "$W$와 $H$에 0이 아닌 무작위 값을 할당 후  \n",
    "곱하여 $WH$의 값이 $V$와 유사한지를 확인 합니다.  \n",
    "유사하지 않다면, 이를 다시 랜덤한 값을 넣어 유사할 때 까지 반복합니다.  \n",
    "\n",
    "이때, $WH$와 $V$ 간 거리를 최소화 하는 방향으로 값을 할당합니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- [차원 축소 - PCA, 주성분분석 (1)](https://excelsior-cjh.tistory.com/167)\n",
    "- [t-SNE를 이용한 차원 감소 (Dimension reduction)](https://bcho.tistory.com/1210?category=555440)  \n",
    "- [NMF 알고리즘을 이용한 유사한 문서 검색과 구현](https://bcho.tistory.com/1216?category=555440)\n",
    "- [차원축소[NMF]](http://blog.naver.com/PostView.nhn?blogId=ynca333&logNo=221255848792&parentCategoryNo=&categoryNo=70&viewDate=&isShowPopularPosts=true&from=search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
