{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Random Forest.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"7u8_UuoOF9ae","colab_type":"text"},"source":["# Random Forest\n","\n","__Random Forest__ 을 설명하기 앞서  \n","__Boostrapping__ 에 대해 설명드리겠습니다.  \n","\n","> __Boostrapping__  \n","__Boostrapping__ 이란,  \n","훈련 데이터를 여러개로 나눈 후  \n","기존 데이터의 개수만큼 데이터 셋을 복원 추출하는 것을 말합니다.  \n","\n","__Random Forest__ 의 경우 __Boostrapping__ 을 이용하여 기본 모델을 생성하며,  \n","__Bagging__ 보다 각 모델들의 분산을 줄여 학습하는 기법입니다.  \n","\n","\n","또한, __Tree__ 모델을 사용하여  \n","\n","데이터 분포에 대한 가정 없어도 되며  \n","데이터 크기가 커도 빠르게 모델을 구축할 수 있습니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vSwJpVWzF9ag","colab_type":"text"},"source":["## 모델 생성 방식\n","1. 데이터를 여러 부분으로 나눕니다.  \n","2. 원 데이터의 크기 만큼 복원 추출합니다.  \n","3. 각 샘플에서 변수를 무작위 추출해 의사결정나무를 만듭니다.  \n","4. 각 모형들의 평균을 이용하여 값을 예측합니다.  \n","\n","<img src=\"./image/Random Forest/Randomforest.gif\" width=\"450\" height=\"450\">"]},{"cell_type":"markdown","metadata":{"id":"S5pKoaYUF9ag","colab_type":"text"},"source":["## Tree의 구조"]},{"cell_type":"markdown","metadata":{"id":"AYEShTvRF9ah","colab_type":"text"},"source":["![structure](./image/Random Forest/structure.png)"]},{"cell_type":"markdown","metadata":{"id":"aa8JtZgWF9ai","colab_type":"text"},"source":["__노드__ : 트리를 구성하는 기본 요소로, 위 그림에서 동그라미.  \n","__간선__ : 노드를 이어주는 선분  \n","__루트 노드__ : 데이터의 분할이 시작되는 최상위 노드, A 노드.  \n","__부모 노드__ : 하위의 노드가 있는 노드    \n","__자식 노드__ : 상위 노드가 있는 노드  \n","__형제 노드__ : 같은 상위 노드를 가진 노드들  \n","__리프 노드__ : 맨 끝 노드  \n","__깊이__ : 루트 노드로 부터 특정 노드 까지의 길이  \n","__높이__ : 루트 노드로 부터 가장 끝 노드 까지의 길이   "]},{"cell_type":"markdown","metadata":{"id":"lJKWBslLF9aj","colab_type":"text"},"source":["## Hyper Parameter"]},{"cell_type":"markdown","metadata":{"id":"FlKVotgSF9aj","colab_type":"text"},"source":["파라미터|설명|비고|초기값\n","---|---|---|---\n","__n_estimators__|의사결정나무의 개수 지정|개수를 늘리면 성능이 좋아지나 시간도 많이 걸림|default = 10\n","__min_samples_split__|노드를 분할하기 위한 최소한의 샘플 데이터 수|과적합 제어에 사용|default = 2\n","__min_saples_leaf__|리프 노드가 되기 위해 필요한 최소한의 샘플 데이터 수|과적합 제어에 사용|default = 1\n","__max_feature__|나무를 분할하는데 사용할 변수의 개수|일반적으로 변수의 개수를 루트로 사용|default = 'auto' (=squrt)\n","__max_depth__|의사결정나무의 깊이 설정|깊이가 길어지면 과적합 위험|default = None\n","__oob_score__|OOB(out of bag) 설정|error율 판단 척도|default = False\n"]},{"cell_type":"markdown","metadata":{"id":"d7Vtlj_hF9ak","colab_type":"text"},"source":["## 코드"]},{"cell_type":"code","metadata":{"id":"8S87DklxF9al","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.ensemble import RandomForestClassifier # 분류 트리\n","from sklearn.ensemble import RandomForestRegressor # 회귀 트리\n","from sklearn.model_selection import train_test_split # train/test set 나누기\n","from sklearn.metrics import accuracy_score # 정확도 측정"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iB3WjP0ZF9ap","colab_type":"code","colab":{}},"source":["data = pd.read_csv('./train.csv')\n","\n","features = list(data.columns.difference('target'))\n","X = data[features] # 설명 변수\n","y =  data['target'] # 반응 변수\n","\n","X_train, X_test, y_train, y_test =\\\n","        train_test_split(X, y, test_size = 0.2, random_state = 2020) # 데이터 * 0.8 = train set / 데이터 * 0.2 = vaild set"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6rpxp5dCF9at","colab_type":"text"},"source":["## 모델 생성"]},{"cell_type":"code","metadata":{"id":"FPoLOqvJF9at","colab_type":"code","colab":{}},"source":["model = RandomForestClassifier()\n","model.fit(X_train, y_train)\n","pred = model.predict(X_test)\n","print('Accuracy : %.2f' %(accuracy_score(y_test, pred) * 100), \"%\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"isyems7OF9aw","colab_type":"code","colab":{}},"source":["model2 = RandomForestClassifier(n_estimators = 200,\n","                                max_depth = 10,\n","                                random_state = 2020,\n","                                oob_score = True)\n","model2.fit(X_train, y_train)\n","pred2 = model2.predict(X_test)\n","print('Accuracy : %.2f' %(accuracy_score(y_test, pred2) * 100), \"%\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xUdRDnK1F9a0","colab_type":"text"},"source":["## 변수 중요도 시각화"]},{"cell_type":"code","metadata":{"id":"0-DagUo1F9a0","colab_type":"code","colab":{}},"source":["imp = model.feature_importances_\n","feature_imp = pd.Series(imp, index = X_train.columns)\n","top_10 = feature_imp.sort_values(ascending = False)[:10]\n","\n","plt.figure(figsize = (18, 8))\n","plt.title('Feature importances')\n","sns.barplot(x = top_10, y = top_10.index)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZwQKdltF9a5","colab_type":"text"},"source":["## Grid search"]},{"cell_type":"code","metadata":{"id":"Tidgq1HkF9a6","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import GridSearchCV"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKzE7njqF9a9","colab_type":"code","colab":{}},"source":["n_estimators = [10, 20, 40, 100]\n","max_features = [2, 4]\n","max_depth = [10]\n","random_state = [2020]\n","\n","param_grid = [\n","    {'n_estimators' : n_estimators, 'max_features' : max_features, 'random_state' : random_state} ,\n","    {'max_depth' : max_depth, 'n_estimators' : n_estimators, 'max_features' : max_features, 'random_state' : random_state}\n","]\n","\n","model = RandomForestClassifier()\n","grid_search = GridSearchCV(model,\n","                           param_grid = param_grid,\n","                           cv = 2,\n","                           scoring = 'accuracy',\n","                           verbose = 1,\n","                           n_jobs = 1)\n","\n","grid_search.fit(X_train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cIC-9vbjF9bA","colab_type":"code","colab":{}},"source":["grid_search.best_params_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"60cEwsrTF9bD","colab_type":"code","colab":{}},"source":["grid_search.best_estimator_"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WDlPZ1CAF9bJ","colab_type":"text"},"source":["## Random Search"]},{"cell_type":"code","metadata":{"id":"EQ3mHhjVF9bJ","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import RandomizedSearchCV\n","n_estimators = [int(i) for i in range(10, 100, 10)]\n","max_features = ['log2', 'auto']\n","max_depth = [int(i) for i in np.linspace(start = 10, stop = 110, num = 11)] # 10에서 110까지 동일한 간격으로 11개 만듦\n","min_sample_split = [2, 5, 10]\n","min_samples_leaf = [1, 2, 4]\n","random_state = [2020]\n","\n","random_grid = {\n","    'n_estimators' : n_estimators,\n","    'max_features' : max_features,\n","    'max_depth' : max_depth,\n","    'min_sample_split' : min_sample_split,\n","    'min_samples_leaf' : min_samples_leaf,\n","    'random_state' : random_state\n","}\n","\n","model = RandomForestClassifier()\n","random_search = RandomizedSearchCV(model,\n","                                   param_distributions = random_grid,\n","                                   cv = 2,\n","                                   n_iter = 10,\n","                                   scoring = 'accuracy',\n","                                   verbose = 2, \n","                                   n_jobs = 4)\n","random_search.fit(X_train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P0Mc_W0OF9bM","colab_type":"text"},"source":["## Reference\n","\n","### Tree\n","- [[자료구조/java] 트리 (Tree)](https://songeunjung92.tistory.com/m/26)\n","\n","### Random Forest\n","- [랜덤 포레스트](https://www.wikiwand.com/ko/%EB%9E%9C%EB%8D%A4_%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8)  \n","- [[Chapter 4. 분류] 랜덤포레스트(Random Forest)](https://injo.tistory.com/30)  \n","- [<MACHINE LEARNING>하이퍼파라미터 튜닝](https://databuzz-team.github.io/2018/12/05/hyperparameter-setting/)\n","- [Hyperparameter Tuning the Random Forest in Python](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)"]},{"cell_type":"code","metadata":{"id":"cOuxNBlaF9bN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}