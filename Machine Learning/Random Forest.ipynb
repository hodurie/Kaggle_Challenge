{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "__Random Forest__ 을 설명하기 앞서  \n",
    "__Boostrapping__ 에 대해 설명드리겠습니다.  \n",
    "\n",
    "> __Boostrapping__  \n",
    "__Boostrapping__ 이란,  \n",
    "훈련 데이터를 여러개로 나눈 후  \n",
    "기존 데이터의 개수만큼 데이터 셋을 복원 추출하는 것을 말합니다.  \n",
    "\n",
    "__Random Forest__ 의 경우 __Boostrapping__ 을 이용하여 기본 모델을 생성하며,  \n",
    "__Bagging__ 보다 각 모델들의 분산을 줄여 학습하는 기법입니다.  \n",
    "\n",
    "\n",
    "또한, __Tree__ 모델을 사용하여  \n",
    "\n",
    "데이터 분포에 대한 가정 없어도 되며  \n",
    "데이터 크기가 커도 빠르게 모델을 구축할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성 방식\n",
    "1. 데이터를 여러 부분으로 나눕니다.  \n",
    "\n",
    "<img src=\"./image/Random Forest/split.png\" width=\"450\" height=\"450\">\n",
    "\n",
    "2. 원 데이터의 크기 만큼 복원 추출합니다.  \n",
    "\n",
    "<img src=\"./image/Random Forest/sampling.png\" width=\"450\" height=\"450\">\n",
    "\n",
    "3. 각 샘플에서 변수를 무작위 추출해 의사결정나무를 만듭니다.  \n",
    "\n",
    "<img src=\"./image/Random Forest/tree.png\" width=\"450\" height=\"450\">\n",
    "\n",
    "4. 각 모형들의 평균을 이용하여 값을 예측합니다.  \n",
    "\n",
    "<img src=\"./image/Random Forest/pred.png\" width=\"450\" height=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree의 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![structure](./image/Random Forest/structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__노드__ : 트리를 구성하는 기본 요소로, 위 그림에서 동그라미.  \n",
    "__간선__ : 노드를 이어주는 선분  \n",
    "__루트 노드__ : 데이터의 분할이 시작되는 최상위 노드, A 노드.  \n",
    "__부모 노드__ : 하위의 노드가 있는 노드    \n",
    "__자식 노드__ : 상위 노드가 있는 노드  \n",
    "__형제 노드__ : 같은 상위 노드를 가진 노드들  \n",
    "__리프 노드__ : 맨 끝 노드  \n",
    "__깊이__ : 루트 노드로 부터 특정 노드 까지의 길이  \n",
    "__높이__ : 루트 노드로 부터 가장 끝 노드 까지의 길이   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터|설명|비고|초기값\n",
    "---|---|---|---\n",
    "__n_estimators__|의사결정나무의 개수 지정|개수를 늘리면 성능이 좋아지나 시간도 많이 걸림|default = 10\n",
    "__min_samples_split__|노드를 분할하기 위한 최소한의 샘플 데이터 수|과적합 제어에 사용|default = 2\n",
    "__min_saples_leaf__|리프 노드가 되기 위해 필요한 최소한의 샘플 데이터 수|과적합 제어에 사용|default = 1\n",
    "__max_feature__|나무를 분할하는데 사용할 변수의 개수|일반적으로 변수의 개수를 루트로 사용|default = 'auto' (=squrt)\n",
    "__max_depth__|의사결정나무의 깊이 설정|깊이가 길어지면 과적합 위험|default = None\n",
    "__oob_score__|OOB(out of bag) 설정|error율 판단 척도|default = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier # 분류 트리\n",
    "from sklearn.ensemble import RandomForestRegressor # 회귀 트리\n",
    "from sklearn.model_selection import train_test_split # train/test set 나누기\n",
    "from sklearn.metrics import accuracy_score # 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train.csv')\n",
    "\n",
    "features = list(data.columns.difference('target'))\n",
    "X = data[features] # 설명 변수\n",
    "y =  data['target'] # 반응 변수\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "        train_test_split(X, y, test_size = 0.2, random_state = 2020) # 데이터 * 0.8 = train set / 데이터 * 0.2 = vaild set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print('Accuracy : %.2f' %(accuracy_score(y_test, pred) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RandomForestClassifier(n_estimators = 200,\n",
    "                                max_depth = 10,\n",
    "                                random_state = 2020,\n",
    "                                oob_score = True)\n",
    "model2.fit(X_train, y_train)\n",
    "pred2 = model2.predict(X_test)\n",
    "print('Accuracy : %.2f' %(accuracy_score(y_test, pred2) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 중요도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = model.feature_importances_\n",
    "feature_imp = pd.Series(imp, index = X_train.columns)\n",
    "top_10 = feature_imp.sort_values(ascending = False)[:10]\n",
    "\n",
    "plt.figure(figsize = (18, 8))\n",
    "plt.title('Feature importances')\n",
    "sns.barplot(x = top_10, y = top_10.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 20, 40, 100]\n",
    "max_features = [2, 4]\n",
    "max_depth = [10]\n",
    "random_state = [2020]\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators' : n_estimators, 'max_features' : max_features, 'random_state' : random_state} ,\n",
    "    {'max_depth' : max_depth, 'n_estimators' : n_estimators, 'max_features' : max_features, 'random_state' : random_state}\n",
    "]\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(model,\n",
    "                           param_grid = param_grid,\n",
    "                           cv = 2,\n",
    "                           scoring = 'accuracy',\n",
    "                           verbose = 1,\n",
    "                           n_jobs = 1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(i) for i in range(10, 100, 10)]\n",
    "max_features = ['log2', 'auto']\n",
    "max_depth = [int(i) for i in np.linspace(start = 10, stop = 110, num = 11)] # 10에서 110까지 동일한 간격으로 11개 만듦\n",
    "min_sample_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "random_state = [2020]\n",
    "\n",
    "random_grid = {\n",
    "    'n_estimators' : n_estimators,\n",
    "    'max_features' : max_features,\n",
    "    'max_depth' : max_depth,\n",
    "    'min_sample_split' : min_sample_split,\n",
    "    'min_samples_leaf' : min_samples_leaf,\n",
    "    'random_state' : random_state\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "random_search = RandomizedSearchCV(model,\n",
    "                                   param_distributions = random_grid,\n",
    "                                   cv = 2,\n",
    "                                   n_iter = 10,\n",
    "                                   scoring = 'accuracy',\n",
    "                                   verbose = 2, \n",
    "                                   n_jobs = 4)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "### Tree\n",
    "- [[자료구조/java] 트리 (Tree)](https://songeunjung92.tistory.com/m/26)\n",
    "\n",
    "### Random Forest\n",
    "- [[Chapter 4. 분류] 랜덤포레스트(Random Forest)](https://injo.tistory.com/30)  \n",
    "- [<MACHINE LEARNING>하이퍼파라미터 튜닝](https://databuzz-team.github.io/2018/12/05/hyperparameter-setting/)\n",
    "- [Hyperparameter Tuning the Random Forest in Python](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
